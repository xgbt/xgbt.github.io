<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Kubernetes 1.29.6 高可用集群部署 | xgbt&#39;s Blog</title>
<meta name="keywords" content="Kubernetes">
<meta name="description" content="架构设计
OS: AlmaLinux 9.1

  
      
          节点名
          IP 地址
      
  
  
      
          zqf-Master01
          10.101.5.110
      
      
          zqf-Master02
          10.101.5.111
      
      
          zqf-Master03
          10.101.5.112
      
      
          zqf-Worker01
          10.101.5.113
      
      
          zqf-Worker02
          10.101.5.114
      
      
          zqf-Worker03
          10.101.5.115
      
      
          zqf-Worker04
          10.101.5.116
      
  

1. 所有节点操作
1.1 基础配置
1.1.1 配置镜像源
1sed -e &#39;s|^mirrorlist=|#mirrorlist=|g&#39; \
2    -e &#39;s|^#\s*baseurl=https://repo.almalinux.org/almalinux|baseurl=https://mirrors.zju.edu.cn/almalinux|g&#39; \
3    -i.bak \
4    /etc/yum.repos.d/almalinux-*.repo
1dnf makecache
1.1.2 配置主机名
1hostnamectl set-hostname &lt;主机名&gt;
添加解析记录，使节点直接使用主机名访问通信">
<meta name="author" content="">
<link rel="canonical" href="/tech/kubernetes/kubernetes-1.29.6-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.4b0be15b6b891613a91dad3a5279f108f18aa855a6dcb49a1e5ff9fade239870.css" integrity="sha256-SwvhW2uJFhOpHa06UnnxCPGKqFWm3LSaHl/5&#43;t4jmHA=" rel="preload stylesheet" as="style">
<link rel="icon" href="/assets/apple-icon.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="/tech/kubernetes/kubernetes-1.29.6-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><style>
@import url('https://fonts.cdnfonts.com/css/code-new-roman');
</style>

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&family=LXGW+WenKai+TC&display=swap"
    rel="stylesheet"><meta property="og:title" content="Kubernetes 1.29.6 高可用集群部署" />
<meta property="og:description" content="架构设计
OS: AlmaLinux 9.1

  
      
          节点名
          IP 地址
      
  
  
      
          zqf-Master01
          10.101.5.110
      
      
          zqf-Master02
          10.101.5.111
      
      
          zqf-Master03
          10.101.5.112
      
      
          zqf-Worker01
          10.101.5.113
      
      
          zqf-Worker02
          10.101.5.114
      
      
          zqf-Worker03
          10.101.5.115
      
      
          zqf-Worker04
          10.101.5.116
      
  

1. 所有节点操作
1.1 基础配置
1.1.1 配置镜像源
1sed -e &#39;s|^mirrorlist=|#mirrorlist=|g&#39; \
2    -e &#39;s|^#\s*baseurl=https://repo.almalinux.org/almalinux|baseurl=https://mirrors.zju.edu.cn/almalinux|g&#39; \
3    -i.bak \
4    /etc/yum.repos.d/almalinux-*.repo
1dnf makecache
1.1.2 配置主机名
1hostnamectl set-hostname &lt;主机名&gt;
添加解析记录，使节点直接使用主机名访问通信" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/tech/kubernetes/kubernetes-1.29.6-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/" /><meta property="article:section" content="tech" />
<meta property="article:published_time" content="2024-11-13T01:09:19+08:00" />
<meta property="article:modified_time" content="2024-11-13T01:09:19+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Kubernetes 1.29.6 高可用集群部署"/>
<meta name="twitter:description" content="架构设计
OS: AlmaLinux 9.1

  
      
          节点名
          IP 地址
      
  
  
      
          zqf-Master01
          10.101.5.110
      
      
          zqf-Master02
          10.101.5.111
      
      
          zqf-Master03
          10.101.5.112
      
      
          zqf-Worker01
          10.101.5.113
      
      
          zqf-Worker02
          10.101.5.114
      
      
          zqf-Worker03
          10.101.5.115
      
      
          zqf-Worker04
          10.101.5.116
      
  

1. 所有节点操作
1.1 基础配置
1.1.1 配置镜像源
1sed -e &#39;s|^mirrorlist=|#mirrorlist=|g&#39; \
2    -e &#39;s|^#\s*baseurl=https://repo.almalinux.org/almalinux|baseurl=https://mirrors.zju.edu.cn/almalinux|g&#39; \
3    -i.bak \
4    /etc/yum.repos.d/almalinux-*.repo
1dnf makecache
1.1.2 配置主机名
1hostnamectl set-hostname &lt;主机名&gt;
添加解析记录，使节点直接使用主机名访问通信"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Tech",
      "item": "/tech/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Kubernetes 1.29.6 高可用集群部署",
      "item": "/tech/kubernetes/kubernetes-1.29.6-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Kubernetes 1.29.6 高可用集群部署",
  "name": "Kubernetes 1.29.6 高可用集群部署",
  "description": "架构设计 OS: AlmaLinux 9.1\n节点名 IP 地址 zqf-Master01 10.101.5.110 zqf-Master02 10.101.5.111 zqf-Master03 10.101.5.112 zqf-Worker01 10.101.5.113 zqf-Worker02 10.101.5.114 zqf-Worker03 10.101.5.115 zqf-Worker04 10.101.5.116 1. 所有节点操作 1.1 基础配置 1.1.1 配置镜像源 1sed -e \u0026#39;s|^mirrorlist=|#mirrorlist=|g\u0026#39; \\ 2 -e \u0026#39;s|^#\\s*baseurl=https://repo.almalinux.org/almalinux|baseurl=https://mirrors.zju.edu.cn/almalinux|g\u0026#39; \\ 3 -i.bak \\ 4 /etc/yum.repos.d/almalinux-*.repo 1dnf makecache 1.1.2 配置主机名 1hostnamectl set-hostname \u0026lt;主机名\u0026gt; 添加解析记录，使节点直接使用主机名访问通信\n",
  "keywords": [
    "Kubernetes"
  ],
  "articleBody": "架构设计 OS: AlmaLinux 9.1\n节点名 IP 地址 zqf-Master01 10.101.5.110 zqf-Master02 10.101.5.111 zqf-Master03 10.101.5.112 zqf-Worker01 10.101.5.113 zqf-Worker02 10.101.5.114 zqf-Worker03 10.101.5.115 zqf-Worker04 10.101.5.116 1. 所有节点操作 1.1 基础配置 1.1.1 配置镜像源 1sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ 2 -e 's|^#\\s*baseurl=https://repo.almalinux.org/almalinux|baseurl=https://mirrors.zju.edu.cn/almalinux|g' \\ 3 -i.bak \\ 4 /etc/yum.repos.d/almalinux-*.repo 1dnf makecache 1.1.2 配置主机名 1hostnamectl set-hostname \u003c主机名\u003e 添加解析记录，使节点直接使用主机名访问通信\n1cat \u003c\u003c EOF \u003e\u003e /etc/hosts 210.101.5.110 zqf-Master01 310.101.5.111 zqf-Master02 410.101.5.112 zqf-Master03 510.101.5.113 zqf-Worker01 610.101.5.114 zqf-Worker02 710.101.5.115 zqf-Worker03 810.101.5.116 zqf-Worker04 9EOF 1.1.3 免密登录配置（新增/可选） 1ssh-keygen -t rsa -b 2048 1ssh-copy-id root@目标节点IP 1.1.4 禁用防火墙 1systemctl stop firewalld \u0026\u0026 systemctl disable firewalld 2systemctl disable --now dnsmasq 1.1.5 禁用 SELINUX 修改配置文件，使 SELINUX=disabled 注意，是 disabled ，不是 disable\n1vim /etc/selinux/config 或者，直接执行下列命令 1sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/sysconfig/selinux 2sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/config 查看系统 SELinux 运行状态 1sestatus 1.1.6 禁用 Swap 分区 Swap 是交换分区，如果机器内存不够，会使用swap分区。\n但是，swap分区性能较低，k8s 默认不允许使用交换分区。\nkubeadm 初始化的时候会检测 swap 状态，未关闭 swap 会导致初始化失败。\n1swapoff -a \u0026\u0026 sysctl -w vm.swappiness=0 2sed -ri '/^[^#]*swap/s@^@#@' /etc/fstab 若 swap 为 0， 说明 swap 关闭成功\n1free -mh 1.1.7 时间同步（新增） 所有节点安装 chrony 1dnf -y install chrony 挑一个节点 (10.101.5.110) 修改配置 1# 配置chrony服务 2vim /etc/chrony.conf 3 4# 指定使用的上游时间服务器地址 5pool ntp.aliyun.com iburst 6 7# 允许访问的服务器 8allow 192.168.10.0/24 其他节点修改上游服务器即可 1# 配置chrony服务 2vim /etc/chrony.conf 3 4# 指定 10.101.5.110 为上游服务器 5pool 10.101.5.110 iburst 启用服务 1systemctl restart chronyd 2systemctl enable chronyd 5. 查看同步状态\n1chronyc sources 1.1.8 配置系统资源限制 1vim /etc/security/limits.conf 添加以下配置，包括最大文件描述符数量、最大进程数量和内存锁定限制\n1* soft nofile 65536 2* hard nofile 131072 3* soft nproc 65535 4* hard nproc 655350 5* soft memlock unlimited 6* hard memlock unlimited 1.1.9 配置内核参数 1sysctl net.core.bpf_jit_limit=452534528 配置 K8S 所需内核参数。\n1cat \u003c /etc/sysctl.d/k8s.conf 2net.ipv4.ip_forward = 1 3net.bridge.bridge-nf-call-iptables = 1 4net.bridge.bridge-nf-call-ip6tables = 1 5fs.may_detach_mounts = 1 6vm.overcommit_memory=1 7vm.panic_on_oom=0 8fs.inotify.max_user_watches=89100 9fs.file-max=52706963 10fs.nr_open=52706963 11net.netfilter.nf_conntrack_max=2310720 12net.ipv4.tcp_keepalive_time = 600 13net.ipv4.tcp_keepalive_probes = 3 14net.ipv4.tcp_keepalive_intvl =15 15net.ipv4.tcp_max_tw_buckets = 36000 16net.ipv4.tcp_tw_reuse = 1 17net.ipv4.tcp_max_orphans = 327680 18net.ipv4.tcp_orphan_retries = 3 19net.ipv4.tcp_syncookies = 1 20net.ipv4.tcp_max_syn_backlog = 16384 21net.ipv4.ip_conntrack_max = 65536 22net.ipv4.tcp_max_syn_backlog = 16384 23net.ipv4.tcp_timestamps = 0 24net.core.somaxconn = 16384 25vm.swappiness=0 26EOF 其中，\n1net.ipv4.ip_forward = 1 2net.bridge.bridge-nf-call-iptables = 1 3net.bridge.bridge-nf-call-ip6tables = 1 也是 Containerd CRI 所需的内核参数。\n加载上述内核参数生效所需要的模块，并加载生效\n1modprobe -- overlay 2modprobe -- br_netfilter 3sysctl --system 1.3 配置 IPVS K8S 集群将使用 ipvs 模式，因此这里事先安装 ipvs 相关组件。\n安装 ipvs 相关软件包 1dnf install -y ipvsadm ipset sysstat conntrack libseccomp 载入模块 1modprobe -- ip_vs 2modprobe -- ip_vs_rr 3modprobe -- ip_vs_wrr 4modprobe -- ip_vs_sh 5modprobe -- nf_conntrack 创建ipvs.conf，设置内核模块的自动载入 1cat \u003c /etc/modules-load.d/ipvs.conf 2ip_vs 3ip_vs_lc 4ip_vs_wlc 5ip_vs_rr 6ip_vs_wrr 7ip_vs_lblc 8ip_vs_lblcr 9ip_vs_dh 10ip_vs_sh 11ip_vs_fo 12ip_vs_nq 13ip_vs_sed 14ip_vs_ftp 15ip_vs_sh 16nf_conntrack 17ip_tables 18ip_set 19xt_set 20ipt_set 21ipt_rpfilter 22ipt_REJECT 23ipip 24EOF 1systemctl enable --now systemd-modules-load.service 1.4 安装 Containerd 安装 Containerd 1dnf install containerd -y 1ctr -v 2ctr containerd.io 1.7.18 生成 containerd 配置文件 1mkdir -p /etc/containerd 2containerd config default | sudo tee /etc/containerd/config.toml 修改 Containerd 使用的 cgroup 为 systemd cgroup driver 1[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc] 2 ... 3 [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options] 4 SystemdCgroup = true 修改 Containerd 使用的 sandbox_image 修改 sandbox 的镜像地址\n1sandbox_image = \"registry.aliyuncs.com/google_containers/pause:3.9\" 配置 Containerd 私服地址跳过 https 验证 1[plugins.\"io.containerd.grpc.v1.cri\".registry.configs] 2 [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"10.101.7.108\".tls] 3 insecure_skip_verify = true 4 [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"szharbor.hithium.cn\".tls] 5 insecure_skip_verify = true 6 7[plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"docker.io\".tls] 8 insecure_skip_verify = true 配置 docker.io 镜像 1 [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors] 2 [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"] 3 endpoint = [\"https://docker.1panel.live\"][plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"10.101.7.108:80\"] 4 endpoint = [\"http://10.101.7.108\"] 使配置生效 1systemctl daemon-reload 2systemctl restart containerd.service 3systemctl enable containerd.service 1.5 安装 K8S 相关组件 https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/\n1cat \u003c /etc/yum.repos.d/kubernetes.repo 2[kubernetes] 3name=Kubernetes 4baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/ 5enabled=1 6gpgcheck=1 7gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/repodata/repomd.xml.key 8EOF 1dnf -y install kubectl kubelet kubeadm 2. 主节点配置 2.1 高可用配置 2.1.1 安装相关组件 安装keepalived, haproxy\n1dnf -y install keepalived haproxy 2.1.2 配置检测脚本文件 该脚本检测本地 8443 端口(haproxy服务)是否正常，若不正常，则停止本地的 Keepalived 服务，VIP飘逸到其它 haproxy 可用的节点，继续提供服务。\n1vim /etc/keepalived/check_apiserver.sh 1#!/bin/sh 2curl -sfk --max-time 2 https://localhost:8443/healthz -o /dev/null 3if [ $? -nq 0] 4then 5 echo \"*** Error GET https://localhost:8443/healthz\" 1\u003e\u00262 6 systemctl stop keepalived 7fi 给脚本文件执行权限\n1chmod +x /etc/keepalived/check_apiserver.sh 2.1.3 配置 keepalived.conf VIP 记得使用节点所在网段，但不使用的 IP 地址\n1vim /etc/keepalived/keepalived.conf 1! Configuration File for keepalived 2global_defs { 3 router_id LVS_DEVEL 4} 5 6# 指定检测脚本: 7# script: 脚本路径; 8# interval: 脚本执行时间; 9# weight: 权重; 10# fall: 连续检测失败多少次之后认定节点不可用; 11# rise: 连续检测成功多少次认为节点恢复正常。 12vrrp_script check_apiserver { 13 script \"/etc/keepalived/check_apiserver.sh\" 14 interval 3 15 weight -2 16 fall 10 17 rise 2 18} 19 20# state: 指定MASTER身份, 另外两台Keepalived设置成BACKUP 21# interface: 指定网卡; 22# virtual_router_id: VRRP虚拟路由id, 同一集群的Keepalived节点要相同, 用来识别彼此 23# priority: 优先级, 另外两台Keepalived分别设置成90 70 24# auth_type: VRRP组节点之间认证方式为PASS铭文 25# auth_pass: VRRP组节点之间用来认证通信的密码 26# virtual_ipaddress: VIP 27# track_script: 指定使用的检测脚本名称 28 29vrrp_instance VI_1 { 30 state MASTER 31 interface ens192 32 virtual_router_id 51 33 priority 100 34 authentication { 35 auth_type PASS 36 auth_pass 1111 37 } 38 virtual_ipaddress { 39 10.101.5.2 40 } 41 track_script { 42 check_apiserver 43 } 44} 2.1.4 配置 haproxy.cfg 1vim /etc/haproxy/haproxy.cfg 1#--------------------------------------------------------------------- 2# Global settings 3#--------------------------------------------------------------------- 4global 5 log\tstdout\tformat\traw\tlocal0 6 chroot\t/var/lib/haproxy 7 pidfile\t/var/run/haproxy.pid 8 maxconn\t4000 9 user\thaproxy 10 group\thaproxy 11 12 13#--------------------------------------------------------------------- 14# common defaults that all the 'listen' and 'backend' sections will 15# use if not designated in their block 16#--------------------------------------------------------------------- 17defaults 18 log\tglobal 19 option\thttplog 20 option\tdontlognull 21 timeout\tconnect\t5s 22 timeout\tclient\t35s 23 timeout\tserver\t35s 24 25 26#--------------------------------------------------------------------- 27# apiserver frontend which proxys to the control plane nodes 28#--------------------------------------------------------------------- 29# 主要是这里的bind: 定义haproxy的代理端口为8443。也可以是其它。 30frontend\tapiserver 31\tbind\t*:8443 32\tmode\ttcp 33\toption\ttcplog 34\tdefault_backend\tapiserverbackend 35 36 37#--------------------------------------------------------------------- 38# round robin balancing for apiserver 39#--------------------------------------------------------------------- 40# 以下是后端相关配置, 关键参数解释如下 41# mode tcp: 设置与后端服务通信的模式为TCP 42# balance roundrobin: 轮询方式 43# inter 10s: 检查间隔为10秒。 44# downinter 5s: 当服务被标记为不可用后，每5秒检查一次是否恢复。 45# rise 2: 在将服务器标记为上线之前，服务器必须连续2次成功响应检查。 46# fall 2: 在将服务器标记为下线之前，服务器必须连续2次失败响应检查。 47# slowstart 60s: 慢启动时间为60秒，用于控制新服务器上线后逐渐增加其权重。 48# maxconn 250: 每个服务器的最大并发连接数为250。 49# maxqueue 256: 后端队列的最大长度为256。 50# weight 100: 服务器的默认权重为100。 51# server 定义后端的服务器列表。 52 53 54backend\tapiserverbackend 55\toption\ttcplog 56\toption\ttcp-check 57\tmode\ttcp 58\tbalance\troundrobin 59\tdefault-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100 60\tserver\tzqf-Master01\t10.101.5.110:6443\tcheck 61\tserver\tzqf-Master02\t10.101.5.111:6443\tcheck 62\tserver\tzqf-Master03\t10.101.5.112:6443\tcheck 2.1.5 启动服务并验证 启动服务 1systemctl enable --now keepalived 2systemctl enable --now haproxy 验证 停止 master01 上的 keepalived 服务后， 虚拟 IP 192.168.10.240/32 会移动到 moster02。 恢复 master01 上的 keepalived 服务后， 虚拟 IP 192.168.10.240/32 会移动回 moster01。\n1[root@zqf-Master01 ~]# ip a | grep ens 22: ens192: mtu 1500 qdisc mq state UP group default qlen 1000 3 inet 10.101.5.110/24 brd 10.101.5.255 scope global noprefixroute ens192 4 inet 192.168.10.240/32 scope global ens192 5 6[root@zqf-Master02 keepalived]# ip a | grep ens 72: ens192: mtu 1500 qdisc mq state UP group default qlen 1000 8 inet 10.101.5.111/24 brd 10.101.5.255 scope global noprefixroute ens192 2.2 基于 kubeadm 安装集群 2.2.1 提前拉取镜像 1kubeadm config images pull --image-repository registry.aliyuncs.com/google_containers 2.2.2 修改 kubeadm 配置文件 1kubeadm config print init-defaults \u003e kubeadm-init.yaml 配置项 描述 advertiseAddress 指定本机地址 name 指定本机的主机名 controlPlaneEndpoint 指定控制面的通信地址，这里写 VIP 地址 imageRepository 指定下载 Kubernetes 组件的镜像仓库地址, 默认访问国外的仓库, 这里需要修改为国内的镜像仓库源 kubernetesVersion 指定安装的 kubernetes 版本 serviceSubnet 指定 Kubernetes 的 Service 资源分配的网段, 网段不能与真实机和 Pod 的网段冲突。 podSubnet 指定 Kubernetes 的 Pod 资源分配的网段, 网段不能与真实机和 Service 的网段冲突。 需要修改的部分包括：\nlocalAPIEndpoint.advertiseAddress：主节点 IP 地址 nodeRegistration.name：主节点 hostname imageRepository：镜像仓库地址 networking.podSubnet: pod 子网范围 1apiVersion: kubeadm.k8s.io/v1beta3 2bootstrapTokens: 3- groups: 4 - system:bootstrappers:kubeadm:default-node-token 5 token: abcdef.0123456789abcdef 6 ttl: 24h0m0s 7 usages: 8 - signing 9 - authentication 10kind: InitConfiguration 11localAPIEndpoint: 12 advertiseAddress: 10.101.5.110 13 bindPort: 6443 14nodeRegistration: 15 criSocket: unix:///var/run/containerd/containerd.sock 16 imagePullPolicy: IfNotPresent 17 name: zqf-Master01 18 taints: null 19--- 20apiServer: 21 timeoutForControlPlane: 4m0s 22apiVersion: kubeadm.k8s.io/v1beta3 23certificatesDir: /etc/kubernetes/pki 24clusterName: kubernetes 25controllerManager: {} 26dns: {} 27controlPlaneEndpoint: \"10.101.5.2:8443\" 28etcd: 29 local: 30 dataDir: /var/lib/etcd 31imageRepository: registry.aliyuncs.com/google_containers 32kind: ClusterConfiguration 33kubernetesVersion: 1.29.6 34networking: 35 dnsDomain: cluster.local 36 serviceSubnet: 10.96.0.0/12 37 podSubnet: 192.168.0.0/16 38scheduler: {} 39 40# 补充 41--- 42apiVersion: kubeproxy.config.k8s.io/v1alpha1 43kind: KubeProxyConfiguration 44mode: ipvs 45--- 46apiVersion: kubelet.config.k8s.io/v1beta1 47kind: KubeletConfiguration 48cgroupDriver: systemd 2.2.3 初始化 K8S 集群 1kubeadm init --config=kubeadm-init.yaml --upload-certs 其中， --upload-certs 会自动将证书从主控制平面节点复制到将要加入的控制平面节点上。\n然后，根据提示将各个节点加入集群。\n1# 添加master节点的命令 2kubeadm token create --print-join-command --certificate-key 3 4# 添加worker节点的命令获取方式 5kubeadm token create --print-join-command kubeadm token create –print-join-command –ttl 0\n2.2.4 配置 kubectl 1mkdir -p $HOME/.kube 2sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config 3sudo chown $(id -u):$(id -g) $HOME/.kube/config 4# 将以下命令加到.bashrc 5export KUBECONFIG=/etc/kubernetes/admin.conf 其中，admin.conf 是连接 Kubernetes 的认证文件，通过此文件才能连接到 kubernetes，kubectl 也需要这个文件；在 Linux 中，使用 KUBECONFIG 环境变量知道认证文件的所在。\nLinux 中每个用户的环境变量是不同的，如果切换了用户，则也需要设置 KUBECONFIG 环境变量；如果要在别的节点上连接集群，则可以把这个文件复制过去。\n此时，在 master01 上执行 kubectl get no 应有\n1[root@zqf-Master01 ~]# kubectl get no 2NAME STATUS ROLES AGE VERSION 3zqf-master01 NotReady control-plane 2m23s v1.29.6 4zqf-master02 NotReady control-plane 101s v1.29.6 5zqf-master03 NotReady control-plane 101s v1.29.6 6zqf-worker01 NotReady 67s v1.29.6 7zqf-worker02 NotReady 65s v1.29.6 8zqf-worker03 NotReady 63s v1.29.6 9zqf-worker04 NotReady 60s v1.29.6 2.3 安装 Calico Calico3.28 版本支持: Kubernetesv1.27-v1.30。\nCalico 的安装方式目前有两种：\n基于 Operator 方式安装，能够管理 Calico 集群的安装，升级，生命周期管理等，但不方便管理镜像地址。（优先） 基于静态资源清单安装，方便，简单，但无法像 Opertaor 一样能够自动管理 Calico 的生命周期。 基于静态资源清单的部署常见的也分为两种：\ncalico.yaml：当 Calico 使用 Kubernetes API 作为数据存储，且集群节点少于 50 个。 calico-typha.yaml: 当 Calico 使用 Kubernetes API 作为数据存储，且集群节点大于 50 个。 https://github.com/projectcalico/calico/blob/master/manifests/calico-typha.yaml\nreplicas: 副本数 , 建议每200个节点1个副本, 生产的话建议3个副本。\n其中，镜像推荐提前拉取到私服，然后修改 imageurl\n安装成功后，如下所示\n1[root@zqf-Master01 ~]# kubectl get po -n kube-system 2NAME READY STATUS RESTARTS AGE 3calico-kube-controllers-7884dfffd6-pdj8v 1/1 Running 0 61s 4calico-node-7q2dp 1/1 Running 0 46s 5calico-node-gdtc4 1/1 Running 0 46s 6calico-node-hndr8 1/1 Running 0 46s 7calico-node-jd9zm 1/1 Running 0 46s 8calico-node-n8z5j 1/1 Running 0 46s 9calico-node-pn4l2 1/1 Running 0 46s 10calico-node-wtqtn 1/1 Running 0 46s 11calico-typha-866db88dc4-8njgj 1/1 Running 0 61s 12calico-typha-866db88dc4-8wd57 1/1 Running 0 61s 13calico-typha-866db88dc4-wnjzh 1/1 Running 0 61s 14coredns-66db75cf8c-96t2p 1/1 Running 0 61s 15coredns-66db75cf8c-xgdf9 1/1 Running 0 61s 16etcd-zqf-master01 1/1 Running 1 53m 17etcd-zqf-master02 1/1 Running 0 52m 18etcd-zqf-master03 1/1 Running 0 52m 19kube-apiserver-zqf-master01 1/1 Running 1 53m 20kube-apiserver-zqf-master02 1/1 Running 0 52m 21kube-apiserver-zqf-master03 1/1 Running 0 52m 22kube-controller-manager-zqf-master01 1/1 Running 1 53m 23kube-controller-manager-zqf-master02 1/1 Running 0 52m 24kube-controller-manager-zqf-master03 1/1 Running 0 52m 25kube-proxy-75sbq 1/1 Running 0 37s 26kube-proxy-g2nqd 1/1 Running 0 45s 27kube-proxy-jqd92 1/1 Running 0 40s 28kube-proxy-kwxcb 1/1 Running 0 44s 29kube-proxy-lhtvl 1/1 Running 0 38s 30kube-proxy-vkv5v 1/1 Running 0 43s 31kube-proxy-ws2fl 1/1 Running 0 41s 32kube-scheduler-zqf-master01 1/1 Running 1 53m 33kube-scheduler-zqf-master02 1/1 Running 0 52m 34kube-scheduler-zqf-master03 1/1 Running 0 52m 1[root@zqf-Master01 ~]# kubectl get node 2NAME STATUS ROLES AGE VERSION 3zqf-master01 Ready control-plane 54m v1.29.6 4zqf-master02 Ready control-plane 53m v1.29.6 5zqf-master03 Ready control-plane 53m v1.29.6 6zqf-worker01 Ready 52m v1.29.6 7zqf-worker02 Ready 52m v1.29.6 8zqf-worker03 Ready 52m v1.29.6 9zqf-worker04 Ready 52m v1.29.6 2.4 配置 kubectl 命令补全 1dnf install -y bash-completion 2source /usr/share/bash-completion/bash_completion 3source \u003c(kubectl completion bash) 4echo \"source \u003c(kubectl completion bash)\" \u003e\u003e ~/.bashrc 3. 清除 kubeadm 环境 1kubeadm reset cleanup-node 2y 3kubeadm reset 4y 5rm -rf /etc/cni/net.d 6ipvsadm --clear 7rm -rf $HOME/.kube/config ",
  "wordCount" : "3290",
  "inLanguage": "zh",
  "datePublished": "2024-11-13T01:09:19+08:00",
  "dateModified": "2024-11-13T01:09:19+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/tech/kubernetes/kubernetes-1.29.6-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "xgbt's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "/assets/apple-icon.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="xgbt&#39;s Blog (Alt + H)">xgbt&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="/" title="🏠主页">
                    <span>🏠主页</span>
                </a>
            </li>
            <li>
                <a href="/search" title="🔍搜索">
                    <span>🔍搜索</span>
                </a>
            </li>
            <li>
                <a href="/tags" title="🏷️标签">
                    <span>🏷️标签</span>
                </a>
            </li>
            <li>
                <a href="/archives" title="📦归档">
                    <span>📦归档</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="/">主页</a>&nbsp;»&nbsp;<a href="/tech/">Tech</a></div>
    <h1 class="post-title entry-hint-parent">
      Kubernetes 1.29.6 高可用集群部署
    </h1>
    <div class="post-meta"><span title='2024-11-13 01:09:19 +0800 CST'>十一月 13, 2024</span>

</div>
  </header> <aside id="toc-container" class="toc-container wide">
        <div class="toc">
            <details  open>
                <summary accesskey="c" title="(Alt + C)">
                    <span class="details">目录</span>
                </summary>

                <div class="inner"><ul>
                        <li>
                            <a href="#%e6%9e%b6%e6%9e%84%e8%ae%be%e8%ae%a1" aria-label="架构设计">架构设计</a></li>
                        <li>
                            <a href="#1-%e6%89%80%e6%9c%89%e8%8a%82%e7%82%b9%e6%93%8d%e4%bd%9c" aria-label="1. 所有节点操作">1. 所有节点操作</a><ul>
                                    
                        <li>
                            <a href="#11-%e5%9f%ba%e7%a1%80%e9%85%8d%e7%bd%ae" aria-label="1.1 基础配置">1.1 基础配置</a><ul>
                                    
                        <li>
                            <a href="#111-%e9%85%8d%e7%bd%ae%e9%95%9c%e5%83%8f%e6%ba%90" aria-label="1.1.1 配置镜像源">1.1.1 配置镜像源</a></li>
                        <li>
                            <a href="#112-%e9%85%8d%e7%bd%ae%e4%b8%bb%e6%9c%ba%e5%90%8d" aria-label="1.1.2 配置主机名">1.1.2 配置主机名</a></li>
                        <li>
                            <a href="#113-%e5%85%8d%e5%af%86%e7%99%bb%e5%bd%95%e9%85%8d%e7%bd%ae%e6%96%b0%e5%a2%9e%e5%8f%af%e9%80%89" aria-label="1.1.3 免密登录配置（新增/可选）">1.1.3 免密登录配置（新增/可选）</a></li>
                        <li>
                            <a href="#114-%e7%a6%81%e7%94%a8%e9%98%b2%e7%81%ab%e5%a2%99" aria-label="1.1.4 禁用防火墙">1.1.4 禁用防火墙</a></li>
                        <li>
                            <a href="#115-%e7%a6%81%e7%94%a8-selinux" aria-label="1.1.5 禁用 SELINUX">1.1.5 禁用 SELINUX</a></li>
                        <li>
                            <a href="#116-%e7%a6%81%e7%94%a8-swap-%e5%88%86%e5%8c%ba" aria-label="1.1.6 禁用 Swap 分区">1.1.6 禁用 Swap 分区</a></li>
                        <li>
                            <a href="#117-%e6%97%b6%e9%97%b4%e5%90%8c%e6%ad%a5%e6%96%b0%e5%a2%9e" aria-label="1.1.7 时间同步（新增）">1.1.7 时间同步（新增）</a></li>
                        <li>
                            <a href="#118-%e9%85%8d%e7%bd%ae%e7%b3%bb%e7%bb%9f%e8%b5%84%e6%ba%90%e9%99%90%e5%88%b6" aria-label="1.1.8 配置系统资源限制">1.1.8 配置系统资源限制</a></li>
                        <li>
                            <a href="#119-%e9%85%8d%e7%bd%ae%e5%86%85%e6%a0%b8%e5%8f%82%e6%95%b0" aria-label="1.1.9 配置内核参数">1.1.9 配置内核参数</a></li></ul>
                        </li>
                        <li>
                            <a href="#13-%e9%85%8d%e7%bd%ae-ipvs" aria-label="1.3 配置 IPVS">1.3 配置 IPVS</a></li>
                        <li>
                            <a href="#14-%e5%ae%89%e8%a3%85-containerd" aria-label="1.4 安装 Containerd">1.4 安装 Containerd</a></li>
                        <li>
                            <a href="#15-%e5%ae%89%e8%a3%85-k8s-%e7%9b%b8%e5%85%b3%e7%bb%84%e4%bb%b6" aria-label="1.5 安装 K8S 相关组件">1.5 安装 K8S 相关组件</a></li></ul>
                        </li>
                        <li>
                            <a href="#2-%e4%b8%bb%e8%8a%82%e7%82%b9%e9%85%8d%e7%bd%ae" aria-label="2. 主节点配置">2. 主节点配置</a><ul>
                                    
                        <li>
                            <a href="#21-%e9%ab%98%e5%8f%af%e7%94%a8%e9%85%8d%e7%bd%ae" aria-label="2.1 高可用配置">2.1 高可用配置</a><ul>
                                    
                        <li>
                            <a href="#211-%e5%ae%89%e8%a3%85%e7%9b%b8%e5%85%b3%e7%bb%84%e4%bb%b6" aria-label="2.1.1 安装相关组件">2.1.1 安装相关组件</a></li>
                        <li>
                            <a href="#212-%e9%85%8d%e7%bd%ae%e6%a3%80%e6%b5%8b%e8%84%9a%e6%9c%ac%e6%96%87%e4%bb%b6" aria-label="2.1.2 配置检测脚本文件">2.1.2 <strong>配置检测脚本文件</strong></a></li>
                        <li>
                            <a href="#213-%e9%85%8d%e7%bd%ae-keepalivedconf" aria-label="2.1.3 配置 keepalived.conf">2.1.3 配置 keepalived.conf</a></li>
                        <li>
                            <a href="#214-%e9%85%8d%e7%bd%ae-haproxycfg" aria-label="2.1.4 配置 haproxy.cfg">2.1.4 配置 haproxy.cfg</a></li>
                        <li>
                            <a href="#215-%e5%90%af%e5%8a%a8%e6%9c%8d%e5%8a%a1%e5%b9%b6%e9%aa%8c%e8%af%81" aria-label="2.1.5 启动服务并验证">2.1.5 启动服务并验证</a></li></ul>
                        </li>
                        <li>
                            <a href="#22-%e5%9f%ba%e4%ba%8e-kubeadm-%e5%ae%89%e8%a3%85%e9%9b%86%e7%be%a4" aria-label="2.2 基于 kubeadm 安装集群">2.2 基于 kubeadm 安装集群</a><ul>
                                    
                        <li>
                            <a href="#221-%e6%8f%90%e5%89%8d%e6%8b%89%e5%8f%96%e9%95%9c%e5%83%8f" aria-label="2.2.1 提前拉取镜像">2.2.1 提前拉取镜像</a></li>
                        <li>
                            <a href="#222-%e4%bf%ae%e6%94%b9-kubeadm-%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6" aria-label="2.2.2 修改 kubeadm 配置文件">2.2.2 修改 kubeadm 配置文件</a></li>
                        <li>
                            <a href="#223-%e5%88%9d%e5%a7%8b%e5%8c%96-k8s-%e9%9b%86%e7%be%a4" aria-label="2.2.3 初始化 K8S 集群">2.2.3 初始化 K8S 集群</a></li>
                        <li>
                            <a href="#224-%e9%85%8d%e7%bd%ae-kubectl" aria-label="2.2.4 配置 kubectl">2.2.4 配置 kubectl</a></li></ul>
                        </li>
                        <li>
                            <a href="#23-%e5%ae%89%e8%a3%85-calico" aria-label="2.3 安装 Calico">2.3 安装 Calico</a></li>
                        <li>
                            <a href="#24-%e9%85%8d%e7%bd%ae-kubectl-%e5%91%bd%e4%bb%a4%e8%a1%a5%e5%85%a8" aria-label="2.4 配置 kubectl 命令补全">2.4 配置 kubectl 命令补全</a></li></ul>
                        </li>
                        <li>
                            <a href="#3-%e6%b8%85%e9%99%a4-kubeadm-%e7%8e%af%e5%a2%83" aria-label="3. 清除 kubeadm 环境">3. 清除 kubeadm 环境</a>
                        </li>
                    </ul>
                </div>
            </details>
        </div>
    </aside>
    <script>
        let activeElement;
        let elements;

        document.addEventListener('DOMContentLoaded', function (event) {
            checkTocPosition();

            elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
            if (elements.length > 0) {
                
                activeElement = elements[0];
                const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
            }

            
            const topLink = document.getElementById('top-link');
            if (topLink) {
                topLink.addEventListener('click', (event) => {
                    
                    event.preventDefault();

                    
                    window.scrollTo({ top: 0, behavior: 'smooth' });
                });
            }
        }, false);

        window.addEventListener('resize', function (event) {
            checkTocPosition();
        }, false);

        window.addEventListener('scroll', () => {
            
            const scrollPosition = window.pageYOffset || document.documentElement.scrollTop;

            
            if (scrollPosition === 0) {
                return;
            }

            
            if (elements && elements.length > 0) {
                
                activeElement = Array.from(elements).find((element) => {
                    if ((getOffsetTop(element) - scrollPosition) > 0 &&
                        (getOffsetTop(element) - scrollPosition) < window.innerHeight / 2) {
                        return element;
                    }
                }) || activeElement;

                elements.forEach(element => {
                    const id = encodeURI(element.getAttribute('id')).toLowerCase();
                    const tocLink = document.querySelector(`.inner ul li a[href="#${id}"]`);
                    if (element === activeElement) {
                        tocLink.classList.add('active');

                        
                        const tocContainer = document.querySelector('.toc .inner');
                        const linkOffsetTop = tocLink.offsetTop;
                        const containerHeight = tocContainer.clientHeight;
                        const linkHeight = tocLink.clientHeight;

                        
                        const scrollPosition = linkOffsetTop - (containerHeight / 2) + (linkHeight / 2);
                        tocContainer.scrollTo({ top: scrollPosition, behavior: 'smooth' });
                    } else {
                        tocLink.classList.remove('active');
                    }
                });
            }
        }, false);

        const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
        const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
        const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

        function checkTocPosition() {
            const width = document.body.scrollWidth;

            if (width - main - (toc * 2) - (gap * 4) > 0) {
                document.getElementById("toc-container").classList.add("wide");
            } else {
                document.getElementById("toc-container").classList.remove("wide");
            }
        }

        function getOffsetTop(element) {
            if (!element.getClientRects().length) {
                return 0;
            }
            let rect = element.getBoundingClientRect();
            let win = element.ownerDocument.defaultView;
            return rect.top + win.pageYOffset;
        }

    </script>
  <div class="post-content"><h1 id="架构设计">架构设计<a hidden class="anchor" aria-hidden="true" href="#架构设计">#</a></h1>
<p>OS: AlmaLinux 9.1</p>
<table>
  <thead>
      <tr>
          <th>节点名</th>
          <th>IP 地址</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>zqf-Master01</td>
          <td>10.101.5.110</td>
      </tr>
      <tr>
          <td>zqf-Master02</td>
          <td>10.101.5.111</td>
      </tr>
      <tr>
          <td>zqf-Master03</td>
          <td>10.101.5.112</td>
      </tr>
      <tr>
          <td>zqf-Worker01</td>
          <td>10.101.5.113</td>
      </tr>
      <tr>
          <td>zqf-Worker02</td>
          <td>10.101.5.114</td>
      </tr>
      <tr>
          <td>zqf-Worker03</td>
          <td>10.101.5.115</td>
      </tr>
      <tr>
          <td>zqf-Worker04</td>
          <td>10.101.5.116</td>
      </tr>
  </tbody>
</table>
<h1 id="1-所有节点操作">1. 所有节点操作<a hidden class="anchor" aria-hidden="true" href="#1-所有节点操作">#</a></h1>
<h2 id="11-基础配置">1.1 基础配置<a hidden class="anchor" aria-hidden="true" href="#11-基础配置">#</a></h2>
<h3 id="111-配置镜像源">1.1.1 配置镜像源<a hidden class="anchor" aria-hidden="true" href="#111-配置镜像源">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">sed -e <span class="s1">&#39;s|^mirrorlist=|#mirrorlist=|g&#39;</span> <span class="se">\
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="se"></span>    -e <span class="s1">&#39;s|^#\s*baseurl=https://repo.almalinux.org/almalinux|baseurl=https://mirrors.zju.edu.cn/almalinux|g&#39;</span> <span class="se">\
</span></span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="se"></span>    -i.bak <span class="se">\
</span></span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="se"></span>    /etc/yum.repos.d/almalinux-*.repo
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">dnf makecache
</span></span></code></pre></div><h3 id="112-配置主机名">1.1.2 配置主机名<a hidden class="anchor" aria-hidden="true" href="#112-配置主机名">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">hostnamectl set-hostname &lt;主机名&gt;
</span></span></code></pre></div><p>添加解析记录，使节点直接使用主机名访问通信</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">cat <span class="s">&lt;&lt; EOF &gt;&gt; /etc/hosts
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="s">10.101.5.110 zqf-Master01
</span></span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="s">10.101.5.111 zqf-Master02
</span></span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="s">10.101.5.112 zqf-Master03
</span></span></span><span class="line"><span class="ln">5</span><span class="cl"><span class="s">10.101.5.113 zqf-Worker01
</span></span></span><span class="line"><span class="ln">6</span><span class="cl"><span class="s">10.101.5.114 zqf-Worker02
</span></span></span><span class="line"><span class="ln">7</span><span class="cl"><span class="s">10.101.5.115 zqf-Worker03
</span></span></span><span class="line"><span class="ln">8</span><span class="cl"><span class="s">10.101.5.116 zqf-Worker04
</span></span></span><span class="line"><span class="ln">9</span><span class="cl"><span class="s">EOF</span>
</span></span></code></pre></div><h3 id="113-免密登录配置新增可选">1.1.3 免密登录配置（新增/可选）<a hidden class="anchor" aria-hidden="true" href="#113-免密登录配置新增可选">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">ssh-keygen -t rsa -b <span class="m">2048</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">ssh-copy-id root@目标节点IP
</span></span></code></pre></div><h3 id="114-禁用防火墙">1.1.4 禁用防火墙<a hidden class="anchor" aria-hidden="true" href="#114-禁用防火墙">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">systemctl stop firewalld <span class="o">&amp;&amp;</span> systemctl disable firewalld
</span></span><span class="line"><span class="ln">2</span><span class="cl">systemctl disable --now dnsmasq
</span></span></code></pre></div><h3 id="115-禁用-selinux">1.1.5 禁用 SELINUX<a hidden class="anchor" aria-hidden="true" href="#115-禁用-selinux">#</a></h3>
<ol>
<li><strong>修改配置文件，使 SELINUX=disabled</strong></li>
</ol>
<p>注意，是 <code>disabled</code> ，不是 <code>disable</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">vim /etc/selinux/config
</span></span></code></pre></div><ol start="2">
<li><strong>或者，直接执行下列命令</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">sed -i <span class="s1">&#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39;</span> /etc/sysconfig/selinux
</span></span><span class="line"><span class="ln">2</span><span class="cl">sed -i <span class="s1">&#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39;</span> /etc/selinux/config
</span></span></code></pre></div><ol start="3">
<li><strong>查看系统 SELinux 运行状态</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">sestatus
</span></span></code></pre></div><h3 id="116-禁用-swap-分区">1.1.6 禁用 Swap 分区<a hidden class="anchor" aria-hidden="true" href="#116-禁用-swap-分区">#</a></h3>
<p>Swap 是交换分区，如果机器内存不够，会使用swap分区。</p>
<p>但是，swap分区性能较低，k8s 默认不允许使用交换分区。</p>
<p>kubeadm 初始化的时候会检测 swap 状态，未关闭 swap 会导致初始化失败。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">swapoff -a <span class="o">&amp;&amp;</span> sysctl -w vm.swappiness<span class="o">=</span><span class="m">0</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl">sed -ri <span class="s1">&#39;/^[^#]*swap/s@^@#@&#39;</span> /etc/fstab
</span></span></code></pre></div><p>若 swap 为 0， 说明 swap 关闭成功</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">free -mh
</span></span></code></pre></div><h3 id="117-时间同步新增">1.1.7 时间同步（新增）<a hidden class="anchor" aria-hidden="true" href="#117-时间同步新增">#</a></h3>
<ol>
<li><strong>所有节点安装 chrony</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">dnf -y install chrony
</span></span></code></pre></div><ol start="2">
<li><strong>挑一个节点 (10.101.5.110) 修改配置</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl"><span class="c1"># 配置chrony服务</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl">vim /etc/chrony.conf
</span></span><span class="line"><span class="ln">3</span><span class="cl">
</span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="c1"># 指定使用的上游时间服务器地址</span>
</span></span><span class="line"><span class="ln">5</span><span class="cl">pool ntp.aliyun.com iburst
</span></span><span class="line"><span class="ln">6</span><span class="cl">
</span></span><span class="line"><span class="ln">7</span><span class="cl"><span class="c1"># 允许访问的服务器</span>
</span></span><span class="line"><span class="ln">8</span><span class="cl">allow 192.168.10.0/24
</span></span></code></pre></div><ol start="3">
<li><strong>其他节点修改上游服务器即可</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl"><span class="c1"># 配置chrony服务</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl">vim /etc/chrony.conf
</span></span><span class="line"><span class="ln">3</span><span class="cl">
</span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="c1"># 指定 10.101.5.110 为上游服务器</span>
</span></span><span class="line"><span class="ln">5</span><span class="cl">pool 10.101.5.110 iburst
</span></span></code></pre></div><ol start="4">
<li><strong>启用服务</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">systemctl restart chronyd
</span></span><span class="line"><span class="ln">2</span><span class="cl">systemctl <span class="nb">enable</span> chronyd
</span></span></code></pre></div><p><br>
5. <strong>查看同步状态</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">chronyc sources
</span></span></code></pre></div><h3 id="118-配置系统资源限制">1.1.8 配置系统资源限制<a hidden class="anchor" aria-hidden="true" href="#118-配置系统资源限制">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">vim /etc/security/limits.conf
</span></span></code></pre></div><p>添加以下配置，包括最大文件描述符数量、最大进程数量和内存锁定限制</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-text" data-lang="text"><span class="line"><span class="ln">1</span><span class="cl">* soft nofile 65536
</span></span><span class="line"><span class="ln">2</span><span class="cl">* hard nofile 131072
</span></span><span class="line"><span class="ln">3</span><span class="cl">* soft nproc 65535
</span></span><span class="line"><span class="ln">4</span><span class="cl">* hard nproc 655350
</span></span><span class="line"><span class="ln">5</span><span class="cl">* soft memlock unlimited
</span></span><span class="line"><span class="ln">6</span><span class="cl">* hard memlock unlimited
</span></span></code></pre></div><h3 id="119-配置内核参数">1.1.9 配置内核参数<a hidden class="anchor" aria-hidden="true" href="#119-配置内核参数">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">sysctl net.core.bpf_jit_limit<span class="o">=</span><span class="m">452534528</span>
</span></span></code></pre></div><p>配置 K8S 所需内核参数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln"> 1</span><span class="cl">cat <span class="s">&lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf 
</span></span></span><span class="line"><span class="ln"> 2</span><span class="cl"><span class="s">net.ipv4.ip_forward = 1
</span></span></span><span class="line"><span class="ln"> 3</span><span class="cl"><span class="s">net.bridge.bridge-nf-call-iptables = 1
</span></span></span><span class="line"><span class="ln"> 4</span><span class="cl"><span class="s">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span class="line"><span class="ln"> 5</span><span class="cl"><span class="s">fs.may_detach_mounts = 1
</span></span></span><span class="line"><span class="ln"> 6</span><span class="cl"><span class="s">vm.overcommit_memory=1
</span></span></span><span class="line"><span class="ln"> 7</span><span class="cl"><span class="s">vm.panic_on_oom=0
</span></span></span><span class="line"><span class="ln"> 8</span><span class="cl"><span class="s">fs.inotify.max_user_watches=89100
</span></span></span><span class="line"><span class="ln"> 9</span><span class="cl"><span class="s">fs.file-max=52706963
</span></span></span><span class="line"><span class="ln">10</span><span class="cl"><span class="s">fs.nr_open=52706963
</span></span></span><span class="line"><span class="ln">11</span><span class="cl"><span class="s">net.netfilter.nf_conntrack_max=2310720
</span></span></span><span class="line"><span class="ln">12</span><span class="cl"><span class="s">net.ipv4.tcp_keepalive_time = 600
</span></span></span><span class="line"><span class="ln">13</span><span class="cl"><span class="s">net.ipv4.tcp_keepalive_probes = 3
</span></span></span><span class="line"><span class="ln">14</span><span class="cl"><span class="s">net.ipv4.tcp_keepalive_intvl =15
</span></span></span><span class="line"><span class="ln">15</span><span class="cl"><span class="s">net.ipv4.tcp_max_tw_buckets = 36000
</span></span></span><span class="line"><span class="ln">16</span><span class="cl"><span class="s">net.ipv4.tcp_tw_reuse = 1
</span></span></span><span class="line"><span class="ln">17</span><span class="cl"><span class="s">net.ipv4.tcp_max_orphans = 327680
</span></span></span><span class="line"><span class="ln">18</span><span class="cl"><span class="s">net.ipv4.tcp_orphan_retries = 3
</span></span></span><span class="line"><span class="ln">19</span><span class="cl"><span class="s">net.ipv4.tcp_syncookies = 1
</span></span></span><span class="line"><span class="ln">20</span><span class="cl"><span class="s">net.ipv4.tcp_max_syn_backlog = 16384
</span></span></span><span class="line"><span class="ln">21</span><span class="cl"><span class="s">net.ipv4.ip_conntrack_max = 65536
</span></span></span><span class="line"><span class="ln">22</span><span class="cl"><span class="s">net.ipv4.tcp_max_syn_backlog = 16384
</span></span></span><span class="line"><span class="ln">23</span><span class="cl"><span class="s">net.ipv4.tcp_timestamps = 0
</span></span></span><span class="line"><span class="ln">24</span><span class="cl"><span class="s">net.core.somaxconn = 16384
</span></span></span><span class="line"><span class="ln">25</span><span class="cl"><span class="s">vm.swappiness=0
</span></span></span><span class="line"><span class="ln">26</span><span class="cl"><span class="s">EOF</span>
</span></span></code></pre></div><p>其中，</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">net.ipv4.ip_forward = 1
</span></span><span class="line"><span class="ln">2</span><span class="cl">net.bridge.bridge-nf-call-iptables = 1
</span></span><span class="line"><span class="ln">3</span><span class="cl">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></code></pre></div><p>也是 Containerd CRI 所需的内核参数。</p>
<p><strong>加载上述内核参数生效所需要的模块，并加载生效</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">modprobe -- overlay
</span></span><span class="line"><span class="ln">2</span><span class="cl">modprobe -- br_netfilter
</span></span><span class="line"><span class="ln">3</span><span class="cl">sysctl --system
</span></span></code></pre></div><h2 id="13-配置-ipvs">1.3 配置 IPVS<a hidden class="anchor" aria-hidden="true" href="#13-配置-ipvs">#</a></h2>
<p>K8S 集群将使用 ipvs 模式，因此这里事先安装 ipvs 相关组件。</p>
<ol>
<li><strong>安装 ipvs 相关软件包</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">dnf install -y ipvsadm ipset sysstat conntrack libseccomp
</span></span></code></pre></div><ol start="2">
<li><strong>载入模块</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">modprobe -- ip_vs
</span></span><span class="line"><span class="ln">2</span><span class="cl">modprobe -- ip_vs_rr
</span></span><span class="line"><span class="ln">3</span><span class="cl">modprobe -- ip_vs_wrr
</span></span><span class="line"><span class="ln">4</span><span class="cl">modprobe -- ip_vs_sh
</span></span><span class="line"><span class="ln">5</span><span class="cl">modprobe -- nf_conntrack
</span></span></code></pre></div><ol start="3">
<li><strong>创建ipvs.conf，设置内核模块的自动载入</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln"> 1</span><span class="cl">cat <span class="s">&lt;&lt;EOF &gt; /etc/modules-load.d/ipvs.conf 
</span></span></span><span class="line"><span class="ln"> 2</span><span class="cl"><span class="s">ip_vs
</span></span></span><span class="line"><span class="ln"> 3</span><span class="cl"><span class="s">ip_vs_lc
</span></span></span><span class="line"><span class="ln"> 4</span><span class="cl"><span class="s">ip_vs_wlc
</span></span></span><span class="line"><span class="ln"> 5</span><span class="cl"><span class="s">ip_vs_rr
</span></span></span><span class="line"><span class="ln"> 6</span><span class="cl"><span class="s">ip_vs_wrr
</span></span></span><span class="line"><span class="ln"> 7</span><span class="cl"><span class="s">ip_vs_lblc
</span></span></span><span class="line"><span class="ln"> 8</span><span class="cl"><span class="s">ip_vs_lblcr
</span></span></span><span class="line"><span class="ln"> 9</span><span class="cl"><span class="s">ip_vs_dh
</span></span></span><span class="line"><span class="ln">10</span><span class="cl"><span class="s">ip_vs_sh
</span></span></span><span class="line"><span class="ln">11</span><span class="cl"><span class="s">ip_vs_fo
</span></span></span><span class="line"><span class="ln">12</span><span class="cl"><span class="s">ip_vs_nq
</span></span></span><span class="line"><span class="ln">13</span><span class="cl"><span class="s">ip_vs_sed
</span></span></span><span class="line"><span class="ln">14</span><span class="cl"><span class="s">ip_vs_ftp
</span></span></span><span class="line"><span class="ln">15</span><span class="cl"><span class="s">ip_vs_sh
</span></span></span><span class="line"><span class="ln">16</span><span class="cl"><span class="s">nf_conntrack
</span></span></span><span class="line"><span class="ln">17</span><span class="cl"><span class="s">ip_tables
</span></span></span><span class="line"><span class="ln">18</span><span class="cl"><span class="s">ip_set
</span></span></span><span class="line"><span class="ln">19</span><span class="cl"><span class="s">xt_set
</span></span></span><span class="line"><span class="ln">20</span><span class="cl"><span class="s">ipt_set
</span></span></span><span class="line"><span class="ln">21</span><span class="cl"><span class="s">ipt_rpfilter
</span></span></span><span class="line"><span class="ln">22</span><span class="cl"><span class="s">ipt_REJECT
</span></span></span><span class="line"><span class="ln">23</span><span class="cl"><span class="s">ipip
</span></span></span><span class="line"><span class="ln">24</span><span class="cl"><span class="s">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">systemctl <span class="nb">enable</span> --now systemd-modules-load.service
</span></span></code></pre></div><h2 id="14-安装-containerd">1.4 安装 Containerd<a hidden class="anchor" aria-hidden="true" href="#14-安装-containerd">#</a></h2>
<ol>
<li><strong>安装 Containerd</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">dnf install containerd -y 
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">ctr -v
</span></span><span class="line"><span class="ln">2</span><span class="cl">ctr containerd.io 1.7.18
</span></span></code></pre></div><ol start="2">
<li><strong>生成 containerd 配置文件</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">mkdir -p /etc/containerd
</span></span><span class="line"><span class="ln">2</span><span class="cl">containerd config default <span class="p">|</span> sudo tee /etc/containerd/config.toml
</span></span></code></pre></div><ol start="3">
<li><strong>修改 Containerd 使用的 cgroup 为 systemd cgroup driver</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">[plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc]  
</span></span><span class="line"><span class="ln">2</span><span class="cl">  ...  
</span></span><span class="line"><span class="ln">3</span><span class="cl">  [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc.options]  
</span></span><span class="line"><span class="ln">4</span><span class="cl">    SystemdCgroup = true
</span></span></code></pre></div><ol start="4">
<li><strong>修改 Containerd 使用的 sandbox_image</strong></li>
</ol>
<p>修改 sandbox 的镜像地址</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="ln">1</span><span class="cl">sandbox_image = &#34;registry.aliyuncs.com/google_containers/pause:3.9&#34;
</span></span></code></pre></div><ol start="5">
<li><strong>配置 Containerd 私服地址跳过 https 验证</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl"><span class="o">[</span>plugins.<span class="s2">&#34;io.containerd.grpc.v1.cri&#34;</span>.registry.configs<span class="o">]</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl">    <span class="o">[</span>plugins.<span class="s2">&#34;io.containerd.grpc.v1.cri&#34;</span>.registry.configs.<span class="s2">&#34;10.101.7.108&#34;</span>.tls<span class="o">]</span>
</span></span><span class="line"><span class="ln">3</span><span class="cl">                <span class="nv">insecure_skip_verify</span> <span class="o">=</span> <span class="nb">true</span>
</span></span><span class="line"><span class="ln">4</span><span class="cl">        <span class="o">[</span>plugins.<span class="s2">&#34;io.containerd.grpc.v1.cri&#34;</span>.registry.configs.<span class="s2">&#34;szharbor.hithium.cn&#34;</span>.tls<span class="o">]</span>
</span></span><span class="line"><span class="ln">5</span><span class="cl">                <span class="nv">insecure_skip_verify</span> <span class="o">=</span> <span class="nb">true</span>
</span></span><span class="line"><span class="ln">6</span><span class="cl">
</span></span><span class="line"><span class="ln">7</span><span class="cl"><span class="o">[</span>plugins.<span class="s2">&#34;io.containerd.grpc.v1.cri&#34;</span>.registry.configs.<span class="s2">&#34;docker.io&#34;</span>.tls<span class="o">]</span>
</span></span><span class="line"><span class="ln">8</span><span class="cl">                <span class="nv">insecure_skip_verify</span> <span class="o">=</span> <span class="nb">true</span>
</span></span></code></pre></div><ol start="6">
<li><strong>配置 docker.io 镜像</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">      <span class="o">[</span>plugins.<span class="s2">&#34;io.containerd.grpc.v1.cri&#34;</span>.registry.mirrors<span class="o">]</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl">        <span class="o">[</span>plugins.<span class="s2">&#34;io.containerd.grpc.v1.cri&#34;</span>.registry.mirrors.<span class="s2">&#34;docker.io&#34;</span><span class="o">]</span>
</span></span><span class="line"><span class="ln">3</span><span class="cl">                <span class="nv">endpoint</span> <span class="o">=</span> <span class="o">[</span><span class="s2">&#34;https://docker.1panel.live&#34;</span><span class="o">][</span>plugins.<span class="s2">&#34;io.containerd.grpc.v1.cri&#34;</span>.registry.mirrors.<span class="s2">&#34;10.101.7.108:80&#34;</span><span class="o">]</span>
</span></span><span class="line"><span class="ln">4</span><span class="cl">                <span class="nv">endpoint</span> <span class="o">=</span> <span class="o">[</span><span class="s2">&#34;http://10.101.7.108&#34;</span><span class="o">]</span>
</span></span></code></pre></div><ol start="7">
<li><strong>使配置生效</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">systemctl daemon-reload
</span></span><span class="line"><span class="ln">2</span><span class="cl">systemctl restart containerd.service
</span></span><span class="line"><span class="ln">3</span><span class="cl">systemctl <span class="nb">enable</span> containerd.service
</span></span></code></pre></div><h2 id="15-安装-k8s-相关组件">1.5 安装 K8S 相关组件<a hidden class="anchor" aria-hidden="true" href="#15-安装-k8s-相关组件">#</a></h2>
<p><a href="https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/">https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">cat <span class="s">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="s">[kubernetes]
</span></span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="s">name=Kubernetes
</span></span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="s">baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/
</span></span></span><span class="line"><span class="ln">5</span><span class="cl"><span class="s">enabled=1
</span></span></span><span class="line"><span class="ln">6</span><span class="cl"><span class="s">gpgcheck=1
</span></span></span><span class="line"><span class="ln">7</span><span class="cl"><span class="s">gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.29/rpm/repodata/repomd.xml.key
</span></span></span><span class="line"><span class="ln">8</span><span class="cl"><span class="s">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">dnf -y install kubectl kubelet kubeadm
</span></span></code></pre></div><h1 id="2-主节点配置">2. 主节点配置<a hidden class="anchor" aria-hidden="true" href="#2-主节点配置">#</a></h1>
<h2 id="21-高可用配置">2.1 高可用配置<a hidden class="anchor" aria-hidden="true" href="#21-高可用配置">#</a></h2>
<h3 id="211-安装相关组件">2.1.1 安装相关组件<a hidden class="anchor" aria-hidden="true" href="#211-安装相关组件">#</a></h3>
<p>安装keepalived, haproxy</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">dnf -y install keepalived haproxy
</span></span></code></pre></div><h3 id="212-配置检测脚本文件">2.1.2 <strong>配置检测脚本文件</strong><a hidden class="anchor" aria-hidden="true" href="#212-配置检测脚本文件">#</a></h3>
<p>该脚本检测本地 8443 端口(haproxy服务)是否正常，若不正常，则停止本地的 Keepalived 服务，VIP飘逸到其它 haproxy 可用的节点，继续提供服务。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">vim /etc/keepalived/check_apiserver.sh
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl"><span class="cp">#!/bin/sh
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="cp"></span>curl -sfk --max-time 2 https://localhost:8443/healthz -o /dev/null  
</span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="k">if</span> <span class="o">[</span> <span class="nv">$?</span> -nq 0<span class="o">]</span>  
</span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="k">then</span>  
</span></span><span class="line"><span class="ln">5</span><span class="cl">        <span class="nb">echo</span> <span class="s2">&#34;*** Error GET https://localhost:8443/healthz&#34;</span> 1&gt;<span class="p">&amp;</span><span class="m">2</span>  
</span></span><span class="line"><span class="ln">6</span><span class="cl">        systemctl stop keepalived  
</span></span><span class="line"><span class="ln">7</span><span class="cl"><span class="k">fi</span>
</span></span></code></pre></div><p><strong>给脚本文件执行权限</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">chmod +x /etc/keepalived/check_apiserver.sh
</span></span></code></pre></div><h3 id="213-配置-keepalivedconf">2.1.3 配置 keepalived.conf<a hidden class="anchor" aria-hidden="true" href="#213-配置-keepalivedconf">#</a></h3>
<p>VIP 记得使用节点所在网段，但不使用的 IP 地址</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">vim /etc/keepalived/keepalived.conf
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln"> 1</span><span class="cl">! Configuration File <span class="k">for</span> keepalived
</span></span><span class="line"><span class="ln"> 2</span><span class="cl">global_defs <span class="o">{</span>
</span></span><span class="line"><span class="ln"> 3</span><span class="cl">    router_id LVS_DEVEL
</span></span><span class="line"><span class="ln"> 4</span><span class="cl"><span class="o">}</span>
</span></span><span class="line"><span class="ln"> 5</span><span class="cl">
</span></span><span class="line"><span class="ln"> 6</span><span class="cl"><span class="c1"># 指定检测脚本:</span>
</span></span><span class="line"><span class="ln"> 7</span><span class="cl"><span class="c1"># script: 脚本路径;</span>
</span></span><span class="line"><span class="ln"> 8</span><span class="cl"><span class="c1"># interval: 脚本执行时间;</span>
</span></span><span class="line"><span class="ln"> 9</span><span class="cl"><span class="c1"># weight: 权重;</span>
</span></span><span class="line"><span class="ln">10</span><span class="cl"><span class="c1"># fall: 连续检测失败多少次之后认定节点不可用;</span>
</span></span><span class="line"><span class="ln">11</span><span class="cl"><span class="c1"># rise: 连续检测成功多少次认为节点恢复正常。</span>
</span></span><span class="line"><span class="ln">12</span><span class="cl">vrrp_script check_apiserver <span class="o">{</span>
</span></span><span class="line"><span class="ln">13</span><span class="cl">  script <span class="s2">&#34;/etc/keepalived/check_apiserver.sh&#34;</span>
</span></span><span class="line"><span class="ln">14</span><span class="cl">  interval <span class="m">3</span>
</span></span><span class="line"><span class="ln">15</span><span class="cl">  weight -2
</span></span><span class="line"><span class="ln">16</span><span class="cl">  fall <span class="m">10</span>
</span></span><span class="line"><span class="ln">17</span><span class="cl">  rise <span class="m">2</span>
</span></span><span class="line"><span class="ln">18</span><span class="cl"><span class="o">}</span>
</span></span><span class="line"><span class="ln">19</span><span class="cl">
</span></span><span class="line"><span class="ln">20</span><span class="cl"><span class="c1"># state: 指定MASTER身份, 另外两台Keepalived设置成BACKUP</span>
</span></span><span class="line"><span class="ln">21</span><span class="cl"><span class="c1"># interface: 指定网卡;</span>
</span></span><span class="line"><span class="ln">22</span><span class="cl"><span class="c1"># virtual_router_id: VRRP虚拟路由id, 同一集群的Keepalived节点要相同, 用来识别彼此</span>
</span></span><span class="line"><span class="ln">23</span><span class="cl"><span class="c1"># priority: 优先级, 另外两台Keepalived分别设置成90 70</span>
</span></span><span class="line"><span class="ln">24</span><span class="cl"><span class="c1"># auth_type: VRRP组节点之间认证方式为PASS铭文</span>
</span></span><span class="line"><span class="ln">25</span><span class="cl"><span class="c1"># auth_pass: VRRP组节点之间用来认证通信的密码</span>
</span></span><span class="line"><span class="ln">26</span><span class="cl"><span class="c1"># virtual_ipaddress: VIP</span>
</span></span><span class="line"><span class="ln">27</span><span class="cl"><span class="c1"># track_script: 指定使用的检测脚本名称</span>
</span></span><span class="line"><span class="ln">28</span><span class="cl">
</span></span><span class="line"><span class="ln">29</span><span class="cl">vrrp_instance VI_1 <span class="o">{</span>
</span></span><span class="line"><span class="ln">30</span><span class="cl">    state MASTER
</span></span><span class="line"><span class="ln">31</span><span class="cl">    interface ens192
</span></span><span class="line"><span class="ln">32</span><span class="cl">    virtual_router_id <span class="m">51</span>
</span></span><span class="line"><span class="ln">33</span><span class="cl">    priority <span class="m">100</span>
</span></span><span class="line"><span class="ln">34</span><span class="cl">    authentication <span class="o">{</span>
</span></span><span class="line"><span class="ln">35</span><span class="cl">        auth_type PASS
</span></span><span class="line"><span class="ln">36</span><span class="cl">        auth_pass <span class="m">1111</span>
</span></span><span class="line"><span class="ln">37</span><span class="cl">    <span class="o">}</span>
</span></span><span class="line"><span class="ln">38</span><span class="cl">    virtual_ipaddress <span class="o">{</span>
</span></span><span class="line"><span class="ln">39</span><span class="cl">        10.101.5.2
</span></span><span class="line"><span class="ln">40</span><span class="cl">    <span class="o">}</span>
</span></span><span class="line"><span class="ln">41</span><span class="cl">    track_script <span class="o">{</span>
</span></span><span class="line"><span class="ln">42</span><span class="cl">        check_apiserver
</span></span><span class="line"><span class="ln">43</span><span class="cl">    <span class="o">}</span>
</span></span><span class="line"><span class="ln">44</span><span class="cl"><span class="o">}</span>
</span></span></code></pre></div><h3 id="214-配置-haproxycfg">2.1.4 配置 haproxy.cfg<a hidden class="anchor" aria-hidden="true" href="#214-配置-haproxycfg">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">vim /etc/haproxy/haproxy.cfg
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln"> 1</span><span class="cl"><span class="c1">#---------------------------------------------------------------------  </span>
</span></span><span class="line"><span class="ln"> 2</span><span class="cl"><span class="c1"># Global settings  </span>
</span></span><span class="line"><span class="ln"> 3</span><span class="cl"><span class="c1">#---------------------------------------------------------------------  </span>
</span></span><span class="line"><span class="ln"> 4</span><span class="cl">global
</span></span><span class="line"><span class="ln"> 5</span><span class="cl">  log	stdout	format	raw	local0
</span></span><span class="line"><span class="ln"> 6</span><span class="cl">  chroot	/var/lib/haproxy
</span></span><span class="line"><span class="ln"> 7</span><span class="cl">  pidfile	/var/run/haproxy.pid
</span></span><span class="line"><span class="ln"> 8</span><span class="cl">  maxconn	<span class="m">4000</span>
</span></span><span class="line"><span class="ln"> 9</span><span class="cl">  user		haproxy
</span></span><span class="line"><span class="ln">10</span><span class="cl">  group		haproxy
</span></span><span class="line"><span class="ln">11</span><span class="cl">
</span></span><span class="line"><span class="ln">12</span><span class="cl">
</span></span><span class="line"><span class="ln">13</span><span class="cl"><span class="c1">#---------------------------------------------------------------------  </span>
</span></span><span class="line"><span class="ln">14</span><span class="cl"><span class="c1"># common defaults that all the &#39;listen&#39; and &#39;backend&#39; sections will  </span>
</span></span><span class="line"><span class="ln">15</span><span class="cl"><span class="c1"># use if not designated in their block  </span>
</span></span><span class="line"><span class="ln">16</span><span class="cl"><span class="c1">#---------------------------------------------------------------------  </span>
</span></span><span class="line"><span class="ln">17</span><span class="cl">defaults
</span></span><span class="line"><span class="ln">18</span><span class="cl">  log		global
</span></span><span class="line"><span class="ln">19</span><span class="cl">  option	httplog
</span></span><span class="line"><span class="ln">20</span><span class="cl">  option	dontlognull
</span></span><span class="line"><span class="ln">21</span><span class="cl">  timeout	connect		5s
</span></span><span class="line"><span class="ln">22</span><span class="cl">  timeout	client		35s
</span></span><span class="line"><span class="ln">23</span><span class="cl">  timeout	server		35s
</span></span><span class="line"><span class="ln">24</span><span class="cl">
</span></span><span class="line"><span class="ln">25</span><span class="cl">
</span></span><span class="line"><span class="ln">26</span><span class="cl"><span class="c1">#---------------------------------------------------------------------  </span>
</span></span><span class="line"><span class="ln">27</span><span class="cl"><span class="c1"># apiserver frontend which proxys to the control plane nodes  </span>
</span></span><span class="line"><span class="ln">28</span><span class="cl"><span class="c1">#---------------------------------------------------------------------  </span>
</span></span><span class="line"><span class="ln">29</span><span class="cl"><span class="c1"># 主要是这里的bind: 定义haproxy的代理端口为8443。也可以是其它。  </span>
</span></span><span class="line"><span class="ln">30</span><span class="cl">frontend	apiserver
</span></span><span class="line"><span class="ln">31</span><span class="cl">	<span class="nb">bind</span>	*:8443
</span></span><span class="line"><span class="ln">32</span><span class="cl">	mode	tcp
</span></span><span class="line"><span class="ln">33</span><span class="cl">	option	tcplog
</span></span><span class="line"><span class="ln">34</span><span class="cl">	default_backend	apiserverbackend
</span></span><span class="line"><span class="ln">35</span><span class="cl">
</span></span><span class="line"><span class="ln">36</span><span class="cl">
</span></span><span class="line"><span class="ln">37</span><span class="cl"><span class="c1">#---------------------------------------------------------------------  </span>
</span></span><span class="line"><span class="ln">38</span><span class="cl"><span class="c1"># round robin balancing for apiserver  </span>
</span></span><span class="line"><span class="ln">39</span><span class="cl"><span class="c1">#---------------------------------------------------------------------  </span>
</span></span><span class="line"><span class="ln">40</span><span class="cl"><span class="c1"># 以下是后端相关配置, 关键参数解释如下  </span>
</span></span><span class="line"><span class="ln">41</span><span class="cl"><span class="c1"># mode tcp: 设置与后端服务通信的模式为TCP  </span>
</span></span><span class="line"><span class="ln">42</span><span class="cl"><span class="c1"># balance roundrobin: 轮询方式  </span>
</span></span><span class="line"><span class="ln">43</span><span class="cl"><span class="c1"># inter 10s: 检查间隔为10秒。  </span>
</span></span><span class="line"><span class="ln">44</span><span class="cl"><span class="c1"># downinter 5s: 当服务被标记为不可用后，每5秒检查一次是否恢复。  </span>
</span></span><span class="line"><span class="ln">45</span><span class="cl"><span class="c1"># rise 2: 在将服务器标记为上线之前，服务器必须连续2次成功响应检查。  </span>
</span></span><span class="line"><span class="ln">46</span><span class="cl"><span class="c1"># fall 2: 在将服务器标记为下线之前，服务器必须连续2次失败响应检查。  </span>
</span></span><span class="line"><span class="ln">47</span><span class="cl"><span class="c1"># slowstart 60s: 慢启动时间为60秒，用于控制新服务器上线后逐渐增加其权重。  </span>
</span></span><span class="line"><span class="ln">48</span><span class="cl"><span class="c1"># maxconn 250: 每个服务器的最大并发连接数为250。  </span>
</span></span><span class="line"><span class="ln">49</span><span class="cl"><span class="c1"># maxqueue 256: 后端队列的最大长度为256。  </span>
</span></span><span class="line"><span class="ln">50</span><span class="cl"><span class="c1"># weight 100: 服务器的默认权重为100。  </span>
</span></span><span class="line"><span class="ln">51</span><span class="cl"><span class="c1"># server 定义后端的服务器列表。  </span>
</span></span><span class="line"><span class="ln">52</span><span class="cl">
</span></span><span class="line"><span class="ln">53</span><span class="cl">
</span></span><span class="line"><span class="ln">54</span><span class="cl">backend		apiserverbackend
</span></span><span class="line"><span class="ln">55</span><span class="cl">	option	tcplog
</span></span><span class="line"><span class="ln">56</span><span class="cl">	option	tcp-check
</span></span><span class="line"><span class="ln">57</span><span class="cl">	mode		tcp
</span></span><span class="line"><span class="ln">58</span><span class="cl">	balance	roundrobin
</span></span><span class="line"><span class="ln">59</span><span class="cl">	default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight <span class="m">100</span>
</span></span><span class="line"><span class="ln">60</span><span class="cl">	server	zqf-Master01	10.101.5.110:6443	check
</span></span><span class="line"><span class="ln">61</span><span class="cl">	server	zqf-Master02	10.101.5.111:6443	check
</span></span><span class="line"><span class="ln">62</span><span class="cl">	server	zqf-Master03	10.101.5.112:6443	check
</span></span></code></pre></div><h3 id="215-启动服务并验证">2.1.5 启动服务并验证<a hidden class="anchor" aria-hidden="true" href="#215-启动服务并验证">#</a></h3>
<ol>
<li><strong>启动服务</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">systemctl <span class="nb">enable</span> --now keepalived
</span></span><span class="line"><span class="ln">2</span><span class="cl">systemctl <span class="nb">enable</span> --now haproxy
</span></span></code></pre></div><ol start="2">
<li><strong>验证</strong></li>
</ol>
<p>停止 master01 上的 keepalived 服务后， 虚拟 IP 192.168.10.240/32 会移动到 moster02。
恢复 master01 上的 keepalived 服务后， 虚拟 IP 192.168.10.240/32 会移动回 moster01。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl"><span class="o">[</span>root@zqf-Master01 ~<span class="o">]</span><span class="c1"># ip a | grep ens</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl">2: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc mq state UP group default qlen <span class="m">1000</span>
</span></span><span class="line"><span class="ln">3</span><span class="cl">    inet 10.101.5.110/24 brd 10.101.5.255 scope global noprefixroute ens192
</span></span><span class="line"><span class="ln">4</span><span class="cl">    inet 192.168.10.240/32 scope global ens192
</span></span><span class="line"><span class="ln">5</span><span class="cl">
</span></span><span class="line"><span class="ln">6</span><span class="cl"><span class="o">[</span>root@zqf-Master02 keepalived<span class="o">]</span><span class="c1"># ip a | grep ens</span>
</span></span><span class="line"><span class="ln">7</span><span class="cl">2: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc mq state UP group default qlen <span class="m">1000</span>
</span></span><span class="line"><span class="ln">8</span><span class="cl">    inet 10.101.5.111/24 brd 10.101.5.255 scope global noprefixroute ens192
</span></span></code></pre></div><h2 id="22-基于-kubeadm-安装集群">2.2 基于 kubeadm 安装集群<a hidden class="anchor" aria-hidden="true" href="#22-基于-kubeadm-安装集群">#</a></h2>
<h3 id="221-提前拉取镜像">2.2.1 提前拉取镜像<a hidden class="anchor" aria-hidden="true" href="#221-提前拉取镜像">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubeadm config images pull --image-repository registry.aliyuncs.com/google_containers
</span></span></code></pre></div><h3 id="222-修改-kubeadm-配置文件">2.2.2 修改 kubeadm 配置文件<a hidden class="anchor" aria-hidden="true" href="#222-修改-kubeadm-配置文件">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubeadm config print init-defaults &gt;  kubeadm-init.yaml
</span></span></code></pre></div><table>
  <thead>
      <tr>
          <th>配置项</th>
          <th>描述</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>advertiseAddress</td>
          <td>指定本机地址</td>
      </tr>
      <tr>
          <td>name</td>
          <td>指定本机的主机名</td>
      </tr>
      <tr>
          <td>controlPlaneEndpoint</td>
          <td>指定控制面的通信地址，这里写 VIP 地址</td>
      </tr>
      <tr>
          <td>imageRepository</td>
          <td>指定下载 Kubernetes 组件的镜像仓库地址, 默认访问国外的仓库, 这里需要修改为国内的镜像仓库源</td>
      </tr>
      <tr>
          <td>kubernetesVersion</td>
          <td>指定安装的 kubernetes 版本</td>
      </tr>
      <tr>
          <td>serviceSubnet</td>
          <td>指定 Kubernetes 的 Service 资源分配的网段, 网段不能与真实机和 Pod 的网段冲突。</td>
      </tr>
      <tr>
          <td>podSubnet</td>
          <td>指定 Kubernetes 的 Pod 资源分配的网段, 网段不能与真实机和 Service 的网段冲突。</td>
      </tr>
  </tbody>
</table>
<p>需要修改的部分包括：</p>
<ul>
<li><code>localAPIEndpoint.advertiseAddress</code>：主节点 IP 地址</li>
<li><code>nodeRegistration.name</code>：主节点 hostname</li>
<li><code>imageRepository</code>：镜像仓库地址</li>
<li><code>networking.podSubnet</code>: pod 子网范围</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="ln"> 1</span><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kubeadm.k8s.io/v1beta3</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 2</span><span class="cl"><span class="w"></span><span class="nt">bootstrapTokens</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 3</span><span class="cl"><span class="w"></span>- <span class="nt">groups</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 4</span><span class="cl"><span class="w">  </span>- <span class="l">system:bootstrappers:kubeadm:default-node-token</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 5</span><span class="cl"><span class="w">  </span><span class="nt">token</span><span class="p">:</span><span class="w"> </span><span class="l">abcdef.0123456789abcdef</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 6</span><span class="cl"><span class="w">  </span><span class="nt">ttl</span><span class="p">:</span><span class="w"> </span><span class="l">24h0m0s</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 7</span><span class="cl"><span class="w">  </span><span class="nt">usages</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 8</span><span class="cl"><span class="w">  </span>- <span class="l">signing</span><span class="w">
</span></span></span><span class="line"><span class="ln"> 9</span><span class="cl"><span class="w">  </span>- <span class="l">authentication</span><span class="w">
</span></span></span><span class="line"><span class="ln">10</span><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">InitConfiguration</span><span class="w">
</span></span></span><span class="line"><span class="ln">11</span><span class="cl"><span class="w"></span><span class="nt">localAPIEndpoint</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">12</span><span class="cl"><span class="w">  </span><span class="nt">advertiseAddress</span><span class="p">:</span><span class="w"> </span><span class="m">10.101.5.110</span><span class="w">
</span></span></span><span class="line"><span class="ln">13</span><span class="cl"><span class="w">  </span><span class="nt">bindPort</span><span class="p">:</span><span class="w"> </span><span class="m">6443</span><span class="w">
</span></span></span><span class="line"><span class="ln">14</span><span class="cl"><span class="w"></span><span class="nt">nodeRegistration</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">15</span><span class="cl"><span class="w">  </span><span class="nt">criSocket</span><span class="p">:</span><span class="w"> </span><span class="l">unix:///var/run/containerd/containerd.sock</span><span class="w">
</span></span></span><span class="line"><span class="ln">16</span><span class="cl"><span class="w">  </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent</span><span class="w">
</span></span></span><span class="line"><span class="ln">17</span><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">zqf-Master01</span><span class="w">
</span></span></span><span class="line"><span class="ln">18</span><span class="cl"><span class="w">  </span><span class="nt">taints</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="w">
</span></span></span><span class="line"><span class="ln">19</span><span class="cl"><span class="w"></span><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="ln">20</span><span class="cl"><span class="w"></span><span class="nt">apiServer</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">21</span><span class="cl"><span class="w">  </span><span class="nt">timeoutForControlPlane</span><span class="p">:</span><span class="w"> </span><span class="l">4m0s</span><span class="w">
</span></span></span><span class="line"><span class="ln">22</span><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kubeadm.k8s.io/v1beta3</span><span class="w">
</span></span></span><span class="line"><span class="ln">23</span><span class="cl"><span class="w"></span><span class="nt">certificatesDir</span><span class="p">:</span><span class="w"> </span><span class="l">/etc/kubernetes/pki</span><span class="w">
</span></span></span><span class="line"><span class="ln">24</span><span class="cl"><span class="w"></span><span class="nt">clusterName</span><span class="p">:</span><span class="w"> </span><span class="l">kubernetes</span><span class="w">
</span></span></span><span class="line"><span class="ln">25</span><span class="cl"><span class="w"></span><span class="nt">controllerManager</span><span class="p">:</span><span class="w"> </span>{}<span class="w">
</span></span></span><span class="line"><span class="ln">26</span><span class="cl"><span class="w"></span><span class="nt">dns</span><span class="p">:</span><span class="w"> </span>{}<span class="w">
</span></span></span><span class="line"><span class="ln">27</span><span class="cl"><span class="w"></span><span class="nt">controlPlaneEndpoint</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;10.101.5.2:8443&#34;</span><span class="w">
</span></span></span><span class="line"><span class="ln">28</span><span class="cl"><span class="w"></span><span class="nt">etcd</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">29</span><span class="cl"><span class="w">  </span><span class="nt">local</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">30</span><span class="cl"><span class="w">    </span><span class="nt">dataDir</span><span class="p">:</span><span class="w"> </span><span class="l">/var/lib/etcd</span><span class="w">
</span></span></span><span class="line"><span class="ln">31</span><span class="cl"><span class="w"></span><span class="nt">imageRepository</span><span class="p">:</span><span class="w"> </span><span class="l">registry.aliyuncs.com/google_containers</span><span class="w">
</span></span></span><span class="line"><span class="ln">32</span><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ClusterConfiguration</span><span class="w">
</span></span></span><span class="line"><span class="ln">33</span><span class="cl"><span class="w"></span><span class="nt">kubernetesVersion</span><span class="p">:</span><span class="w"> </span><span class="m">1.29.6</span><span class="w">
</span></span></span><span class="line"><span class="ln">34</span><span class="cl"><span class="w"></span><span class="nt">networking</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="ln">35</span><span class="cl"><span class="w">  </span><span class="nt">dnsDomain</span><span class="p">:</span><span class="w"> </span><span class="l">cluster.local</span><span class="w">
</span></span></span><span class="line"><span class="ln">36</span><span class="cl"><span class="w">  </span><span class="nt">serviceSubnet</span><span class="p">:</span><span class="w"> </span><span class="m">10.96.0.0</span><span class="l">/12</span><span class="w">
</span></span></span><span class="line"><span class="ln">37</span><span class="cl"><span class="w">  </span><span class="nt">podSubnet</span><span class="p">:</span><span class="w"> </span><span class="m">192.168.0.0</span><span class="l">/16</span><span class="w">
</span></span></span><span class="line"><span class="ln">38</span><span class="cl"><span class="w"></span><span class="nt">scheduler</span><span class="p">:</span><span class="w"> </span>{}<span class="w">
</span></span></span><span class="line"><span class="ln">39</span><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="ln">40</span><span class="cl"><span class="w"></span><span class="c"># 补充</span><span class="w">
</span></span></span><span class="line"><span class="ln">41</span><span class="cl"><span class="w"></span><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="ln">42</span><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kubeproxy.config.k8s.io/v1alpha1</span><span class="w">
</span></span></span><span class="line"><span class="ln">43</span><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">KubeProxyConfiguration</span><span class="w">
</span></span></span><span class="line"><span class="ln">44</span><span class="cl"><span class="w"></span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="l">ipvs</span><span class="w">
</span></span></span><span class="line"><span class="ln">45</span><span class="cl"><span class="w"></span><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="ln">46</span><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kubelet.config.k8s.io/v1beta1</span><span class="w">
</span></span></span><span class="line"><span class="ln">47</span><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">KubeletConfiguration</span><span class="w">
</span></span></span><span class="line"><span class="ln">48</span><span class="cl"><span class="w"></span><span class="nt">cgroupDriver</span><span class="p">:</span><span class="w"> </span><span class="l">systemd</span><span class="w">
</span></span></span></code></pre></div><h3 id="223-初始化-k8s-集群">2.2.3 初始化 K8S 集群<a hidden class="anchor" aria-hidden="true" href="#223-初始化-k8s-集群">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubeadm init --config<span class="o">=</span>kubeadm-init.yaml  --upload-certs
</span></span></code></pre></div><p>其中， <code>--upload-certs</code> 会自动将证书从主控制平面节点复制到将要加入的控制平面节点上。</p>
<p>然后，根据提示将各个节点加入集群。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl"><span class="c1"># 添加master节点的命令</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl">kubeadm token create --print-join-command --certificate-key
</span></span><span class="line"><span class="ln">3</span><span class="cl">
</span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="c1"># 添加worker节点的命令获取方式</span>
</span></span><span class="line"><span class="ln">5</span><span class="cl">kubeadm token create --print-join-command
</span></span></code></pre></div><p>kubeadm token create &ndash;print-join-command &ndash;ttl 0</p>
<h3 id="224-配置-kubectl">2.2.4 配置 kubectl<a hidden class="anchor" aria-hidden="true" href="#224-配置-kubectl">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">mkdir -p <span class="nv">$HOME</span>/.kube
</span></span><span class="line"><span class="ln">2</span><span class="cl">sudo cp -i /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config
</span></span><span class="line"><span class="ln">3</span><span class="cl">sudo chown <span class="k">$(</span>id -u<span class="k">)</span>:<span class="k">$(</span>id -g<span class="k">)</span> <span class="nv">$HOME</span>/.kube/config
</span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="c1"># 将以下命令加到.bashrc</span>
</span></span><span class="line"><span class="ln">5</span><span class="cl"><span class="nb">export</span> <span class="nv">KUBECONFIG</span><span class="o">=</span>/etc/kubernetes/admin.conf
</span></span></code></pre></div><p>其中，admin.conf 是连接 Kubernetes 的认证文件，通过此文件才能连接到 kubernetes，kubectl 也需要这个文件；在 Linux 中，使用 KUBECONFIG 环境变量知道认证文件的所在。</p>
<p>Linux 中每个用户的环境变量是不同的，如果切换了用户，则也需要设置 KUBECONFIG 环境变量；如果要在别的节点上连接集群，则可以把这个文件复制过去。</p>
<p>此时，在 master01 上执行 <code>kubectl get no</code> 应有</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl"><span class="o">[</span>root@zqf-Master01 ~<span class="o">]</span><span class="c1"># kubectl get no</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl">NAME           STATUS     ROLES           AGE     VERSION
</span></span><span class="line"><span class="ln">3</span><span class="cl">zqf-master01   NotReady   control-plane   2m23s   v1.29.6
</span></span><span class="line"><span class="ln">4</span><span class="cl">zqf-master02   NotReady   control-plane   101s    v1.29.6
</span></span><span class="line"><span class="ln">5</span><span class="cl">zqf-master03   NotReady   control-plane   101s    v1.29.6
</span></span><span class="line"><span class="ln">6</span><span class="cl">zqf-worker01   NotReady   &lt;none&gt;          67s     v1.29.6
</span></span><span class="line"><span class="ln">7</span><span class="cl">zqf-worker02   NotReady   &lt;none&gt;          65s     v1.29.6
</span></span><span class="line"><span class="ln">8</span><span class="cl">zqf-worker03   NotReady   &lt;none&gt;          63s     v1.29.6
</span></span><span class="line"><span class="ln">9</span><span class="cl">zqf-worker04   NotReady   &lt;none&gt;          60s     v1.29.6
</span></span></code></pre></div><h2 id="23-安装-calico">2.3 安装 Calico<a hidden class="anchor" aria-hidden="true" href="#23-安装-calico">#</a></h2>
<p>Calico3.28 版本支持: Kubernetesv1.27-v1.30。</p>
<p>Calico 的安装方式目前有两种：</p>
<ul>
<li>基于 Operator 方式安装，能够管理 Calico 集群的安装，升级，生命周期管理等，但不方便管理镜像地址。（优先）</li>
<li>基于静态资源清单安装，方便，简单，但无法像 Opertaor 一样能够自动管理 Calico 的生命周期。</li>
</ul>
<p>基于静态资源清单的部署常见的也分为两种：</p>
<ul>
<li>calico.yaml：当 Calico 使用 Kubernetes API 作为数据存储，且集群节点少于 50 个。</li>
<li>calico-typha.yaml: 当 Calico 使用 Kubernetes API 作为数据存储，且集群节点大于 50 个。</li>
</ul>
<p><a href="https://github.com/projectcalico/calico/blob/master/manifests/calico-typha.yaml">https://github.com/projectcalico/calico/blob/master/manifests/calico-typha.yaml</a></p>
<p>replicas: 副本数 , 建议每200个节点1个副本, 生产的话建议3个副本。</p>
<p>其中，镜像推荐提前拉取到私服，然后修改 imageurl</p>
<p>安装成功后，如下所示</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln"> 1</span><span class="cl"><span class="o">[</span>root@zqf-Master01 ~<span class="o">]</span><span class="c1"># kubectl get po -n kube-system</span>
</span></span><span class="line"><span class="ln"> 2</span><span class="cl">NAME                                       READY   STATUS    RESTARTS   AGE
</span></span><span class="line"><span class="ln"> 3</span><span class="cl">calico-kube-controllers-7884dfffd6-pdj8v   1/1     Running   <span class="m">0</span>          61s
</span></span><span class="line"><span class="ln"> 4</span><span class="cl">calico-node-7q2dp                          1/1     Running   <span class="m">0</span>          46s
</span></span><span class="line"><span class="ln"> 5</span><span class="cl">calico-node-gdtc4                          1/1     Running   <span class="m">0</span>          46s
</span></span><span class="line"><span class="ln"> 6</span><span class="cl">calico-node-hndr8                          1/1     Running   <span class="m">0</span>          46s
</span></span><span class="line"><span class="ln"> 7</span><span class="cl">calico-node-jd9zm                          1/1     Running   <span class="m">0</span>          46s
</span></span><span class="line"><span class="ln"> 8</span><span class="cl">calico-node-n8z5j                          1/1     Running   <span class="m">0</span>          46s
</span></span><span class="line"><span class="ln"> 9</span><span class="cl">calico-node-pn4l2                          1/1     Running   <span class="m">0</span>          46s
</span></span><span class="line"><span class="ln">10</span><span class="cl">calico-node-wtqtn                          1/1     Running   <span class="m">0</span>          46s
</span></span><span class="line"><span class="ln">11</span><span class="cl">calico-typha-866db88dc4-8njgj              1/1     Running   <span class="m">0</span>          61s
</span></span><span class="line"><span class="ln">12</span><span class="cl">calico-typha-866db88dc4-8wd57              1/1     Running   <span class="m">0</span>          61s
</span></span><span class="line"><span class="ln">13</span><span class="cl">calico-typha-866db88dc4-wnjzh              1/1     Running   <span class="m">0</span>          61s
</span></span><span class="line"><span class="ln">14</span><span class="cl">coredns-66db75cf8c-96t2p                   1/1     Running   <span class="m">0</span>          61s
</span></span><span class="line"><span class="ln">15</span><span class="cl">coredns-66db75cf8c-xgdf9                   1/1     Running   <span class="m">0</span>          61s
</span></span><span class="line"><span class="ln">16</span><span class="cl">etcd-zqf-master01                          1/1     Running   <span class="m">1</span>          53m
</span></span><span class="line"><span class="ln">17</span><span class="cl">etcd-zqf-master02                          1/1     Running   <span class="m">0</span>          52m
</span></span><span class="line"><span class="ln">18</span><span class="cl">etcd-zqf-master03                          1/1     Running   <span class="m">0</span>          52m
</span></span><span class="line"><span class="ln">19</span><span class="cl">kube-apiserver-zqf-master01                1/1     Running   <span class="m">1</span>          53m
</span></span><span class="line"><span class="ln">20</span><span class="cl">kube-apiserver-zqf-master02                1/1     Running   <span class="m">0</span>          52m
</span></span><span class="line"><span class="ln">21</span><span class="cl">kube-apiserver-zqf-master03                1/1     Running   <span class="m">0</span>          52m
</span></span><span class="line"><span class="ln">22</span><span class="cl">kube-controller-manager-zqf-master01       1/1     Running   <span class="m">1</span>          53m
</span></span><span class="line"><span class="ln">23</span><span class="cl">kube-controller-manager-zqf-master02       1/1     Running   <span class="m">0</span>          52m
</span></span><span class="line"><span class="ln">24</span><span class="cl">kube-controller-manager-zqf-master03       1/1     Running   <span class="m">0</span>          52m
</span></span><span class="line"><span class="ln">25</span><span class="cl">kube-proxy-75sbq                           1/1     Running   <span class="m">0</span>          37s
</span></span><span class="line"><span class="ln">26</span><span class="cl">kube-proxy-g2nqd                           1/1     Running   <span class="m">0</span>          45s
</span></span><span class="line"><span class="ln">27</span><span class="cl">kube-proxy-jqd92                           1/1     Running   <span class="m">0</span>          40s
</span></span><span class="line"><span class="ln">28</span><span class="cl">kube-proxy-kwxcb                           1/1     Running   <span class="m">0</span>          44s
</span></span><span class="line"><span class="ln">29</span><span class="cl">kube-proxy-lhtvl                           1/1     Running   <span class="m">0</span>          38s
</span></span><span class="line"><span class="ln">30</span><span class="cl">kube-proxy-vkv5v                           1/1     Running   <span class="m">0</span>          43s
</span></span><span class="line"><span class="ln">31</span><span class="cl">kube-proxy-ws2fl                           1/1     Running   <span class="m">0</span>          41s
</span></span><span class="line"><span class="ln">32</span><span class="cl">kube-scheduler-zqf-master01                1/1     Running   <span class="m">1</span>          53m
</span></span><span class="line"><span class="ln">33</span><span class="cl">kube-scheduler-zqf-master02                1/1     Running   <span class="m">0</span>          52m
</span></span><span class="line"><span class="ln">34</span><span class="cl">kube-scheduler-zqf-master03                1/1     Running   <span class="m">0</span>          52m
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl"><span class="o">[</span>root@zqf-Master01 ~<span class="o">]</span><span class="c1"># kubectl get node</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl">NAME           STATUS   ROLES           AGE   VERSION
</span></span><span class="line"><span class="ln">3</span><span class="cl">zqf-master01   Ready    control-plane   54m   v1.29.6
</span></span><span class="line"><span class="ln">4</span><span class="cl">zqf-master02   Ready    control-plane   53m   v1.29.6
</span></span><span class="line"><span class="ln">5</span><span class="cl">zqf-master03   Ready    control-plane   53m   v1.29.6
</span></span><span class="line"><span class="ln">6</span><span class="cl">zqf-worker01   Ready    &lt;none&gt;          52m   v1.29.6
</span></span><span class="line"><span class="ln">7</span><span class="cl">zqf-worker02   Ready    &lt;none&gt;          52m   v1.29.6
</span></span><span class="line"><span class="ln">8</span><span class="cl">zqf-worker03   Ready    &lt;none&gt;          52m   v1.29.6
</span></span><span class="line"><span class="ln">9</span><span class="cl">zqf-worker04   Ready    &lt;none&gt;          52m   v1.29.6
</span></span></code></pre></div><h2 id="24-配置-kubectl-命令补全">2.4 配置 kubectl 命令补全<a hidden class="anchor" aria-hidden="true" href="#24-配置-kubectl-命令补全">#</a></h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="ln">1</span><span class="cl">dnf install -y bash-completion 
</span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="nb">source</span> /usr/share/bash-completion/bash_completion
</span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="nb">source</span> &lt;<span class="o">(</span>kubectl completion bash<span class="o">)</span>
</span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;source &lt;(kubectl completion bash)&#34;</span> &gt;&gt; ~/.bashrc
</span></span></code></pre></div><h1 id="3-清除-kubeadm-环境">3. 清除 kubeadm 环境<a hidden class="anchor" aria-hidden="true" href="#3-清除-kubeadm-环境">#</a></h1>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="ln">1</span><span class="cl">kubeadm reset cleanup-node
</span></span><span class="line"><span class="ln">2</span><span class="cl">y
</span></span><span class="line"><span class="ln">3</span><span class="cl">kubeadm reset
</span></span><span class="line"><span class="ln">4</span><span class="cl">y
</span></span><span class="line"><span class="ln">5</span><span class="cl">rm -rf /etc/cni/net.d
</span></span><span class="line"><span class="ln">6</span><span class="cl">ipvsadm --clear
</span></span><span class="line"><span class="ln">7</span><span class="cl">rm -rf <span class="nv">$HOME</span>/.kube/config
</span></span></code></pre></div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="/tags/kubernetes/">Kubernetes</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="/tech/tools/charles-%E5%AE%89%E5%8D%93%E6%8A%93%E5%8C%85%E9%85%8D%E7%BD%AE/">
    <span class="title">« 上一页</span>
    <br>
    <span>Charles 安卓抓包配置</span>
  </a>
  <a class="next" href="/tech/kubernetes/%E5%9F%BA%E4%BA%8E-kubeadm-%E6%89%8B%E5%8A%A8%E6%9B%B4%E6%96%B0%E8%AF%81%E4%B9%A6/">
    <span class="title">下一页 »</span>
    <br>
    <span>基于 Kubeadm 手动更新证书</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="/">xgbt&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = '复制';

        function copyingDone() {
            copybutton.innerHTML = '已复制！';
            setTimeout(() => {
                copybutton.innerHTML = '复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
